{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7488de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2252a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5586c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=open(\"../data/paperbench/paper.pdf\", \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff16a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "**You are a reproducibility‐assessment assistant.**\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Given a pdf of a scientific paper generate a “reproducibility tree”. The tree should enable the assessment whether a reproduction of the given paper was successful or not. Each node represents one clear, testable requirement for declaring the paper successfully reproduced. \n",
    "\n",
    "**Tree structure rules:**\n",
    "\n",
    "1. **Root node**:\n",
    "    - Always “The paper <paper title> has been reproduced.”\n",
    "2. **Main‐outcome nodes** (children of the root):\n",
    "    - One node per primary result or hypothesis in the paper.\n",
    "3. **Subtask nodes** (descendants of a main outcome):\n",
    "    - Break each outcome into clear, standalone steps (data access, preprocessing, analysis code, statistical tests, figures, robustness checks, etc.).\n",
    "    - Continue decomposing until each node describes a single yes/no criterion.\n",
    "\n",
    "**Hierarchy conventions:**\n",
    "\n",
    "- Nodes at the same level must share the same level of abstraction.\n",
    "- Child nodes refine their parent’s requirement into discrete, verifiable steps.\n",
    "\n",
    "**Your responsibility:**\n",
    "\n",
    "- You will receive, as input the paper and the root node.\n",
    "- Iteratively split the paper into requirements of fine-grained. You should start with the high-level outcomes as child nodes of the root node. For each node you decide whether the  requirement of the node can be split into more narrow subtasks. If so, add these subtasks as child node requirements. If not continue with the next node until finished.\n",
    "- **Formatting:**\n",
    "- Output each child node as a numbered list entry.\n",
    "- Use concise, actionable language.\n",
    "\n",
    "Here is an example of a rubric for the paper: Bridging Data Gaps in Diffusion Models with Adversarial Noise-Based Transfer Learning\n",
    "\n",
    "ROOT: The paper 'Bridging Data Gaps in Diffusion Models with Adversarial Noise-Based Transfer Learning' has been reproduced. 1: Algorithm 1 for training DPMs with Adversarial Noise-based Transfer has been implemented. 1.1: Code has been written to train a binary classifier to predict whether an input $x_t$ originates from the source domain or target domain. 1.2: A binary classifier has been trained to predict whether an input $x_t$ originates from the source domain or target domain. 1.3: The adaptor module from Noguchi & Harada, 2019 has been implemented. 1.4: Code has been written to select training samples from the target dataset, a time-step selected randomly, and standard Gaussian noise for each sample. 1.5: Training samples are drawn from the target dataset, each paired with a randomly selected timestep and standard Gaussian noise. 1.6: Code has been written to compute the adaptive inner maximum as defined in Equation 7. 1.7: The adaptive inner maximum has been computed as defined in Equation 7. 1.8: Code has been written to compute the similarity guided loss as defined in Equation 5. 1.9: The similarity guided loss has been computed as defined in Equation 5. 1.10: Code has been written to update the adaptor module parameters via gradient descent with similarity-guided loss and adversarial noise as the objective. The objective function is defined in Equation 8. 1.11: The adaptor module parameters are updated via gradient descent with similarity-guided loss and adversarial noise as the objective. The objective function is defined in Equation 8. 2: The experimental setup has been implemented, as described in Section 5. 2.1: The experimental setup to evaluate the DDPM and LDM models has been replicated. 2.1.1: Code has been written to fine-tune a pre-trained LDM in the shift module of the U-net. The pre-trained DPM and autoencoders in LDM are kept fixed. 2.1.2: A pre-trained LDM has been fine-tuned in the shift module of the U-net. The pre-trained DPM and autoencoders in LDM are kept fixed. 2.1.3: Code has been written to initialize the parameters of the adapter layer to zero. 2.1.4: The parameters of the adapter layer are initialized to zero. 2.1.5: Code has been written to set the hyper-parameter gamma for similarity-guided training to 5. 2.1.6: The hyper-parameter gamma for similarity-guided training is set to 5. 2.1.7: Code has been written to fine-tune a pre-trained model on ImageNet with a binary classifier head on 10 target domain images. 2.1.8: A pre-trained model on ImageNet is fine-tuned with a binary classifier head on 10 target domain images. 2.1.9: Code has been written to set the hyperparameters $J$ and $\\\\omega$ to 10 and 0.02, respectively, for adversarial noise selection. 2.1.10: The hyperparameters $J$ and $\\\\omega$ are set to 10 and 0.02, respectively, for adversarial noise selection. 2.1.11: The learning rate is set to 0.00005 for DDPM and 0.00001 for LDM. Both models are trained for 300 iterations and a batch size of 40. 2.1.12: The learning rate is set to 0.00005 for DDPM and 0.00001 for LDM. Both models are trained for 300 iterations and a batch size of 40. 2.2: The evaluation metrics have been implemented. 2.2.1: The Intra-LPIPS metric has been implemented. 2.2.1.1: Code has been written to generate 1,000 images from the models. 2.2.1.2: 1,000 images have been generated from the models. 2.2.1.3: Code has been written to assign each image to the training sample with the smallest LPIPS distance. 2.2.1.4: Each image has been assigned to the training sample with the smallest LPIPS distance. 2.2.1.5: The average pair-wise distance within each cluster has computed. The average score from each cluster has been calculated as Intra-LPIPS metric. 2.2.1.6: The average pair-wise distance within each cluster has computed. The average score from each cluster has been calculated as Intra-LPIPS metric. 2.2.2: The FID metric has been implemented. 2.3: The target datasets have been selected for their corresponding source datasets. 2.3.1: Code has been written to load Babies, Sunglasses, Raphael Peale, Sketches, and face paintings from the dataset FFHQ. 2.3.2: Babies, Sunglasses, Raphael Peale, Sketches, and face paintings have been loaded from the dataset FFHQ. 2.3.3: Haunted Houses and Landscape drawings have been loaded from the LSUN dataset. 2.3.4: Haunted Houses and Landscape drawings have been loaded from the LSUN dataset. 2.4: The baseline models used in Table 1 have been implemented by adapting pre-existing implementations from the StyleGAN2 codebase. 2.4.1: TGAN has been implemented by adapting the StyleGAN2 codebase. 2.4.2: TGAN+ADA has been implemented by adapting the StyleGAN2 codebase. 2.4.3: EWC has been implemented by adapting the StyleGAN2 codebase. 2.4.4: CDC has been implemented by adapting the StyleGAN2 codebase. 2.4.5: DCL has been implemented by adapting the StyleGAN2 codebase. 2.4.6: DDPM-PA has been implemented by adapting the StyleGAN2 codebase. 3: Figure 2 has been replicated. 3.1: Code has been written to train a diffusion model to generate data from a 2-dimensional Gaussian distribution with mean [1, 1] and unit variance. 3.2: A diffusion model has been trained to generate data from a 2-dimensional Gaussian distribution with mean [1, 1] and unit variance. 3.3: Code has been written to transfer the trained model to generate samples from a 2-dimensional Gaussian distribution with a mean of [-1, -1] and unit variance using three methods: DDPM, DDPM-ANT w/o AN, and DDPM-ANT. 3.4: The trained model has been transferred to generate samples from a 2-dimensional Gaussian distribution with a mean of [-1, -1] and unit variance using three methods: DDPM, DDPM-ANT w/o AN, and DDPM-ANT. 3.5: Figure 2a has been replicated. 3.5.1: Code has been written to calculate the gradient direction used as reference using 10,000 samples. 3.5.2: The gradient direction used as reference has been calculated using 10,000 samples. 3.5.3: Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM. 3.5.4: The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM. 3.5.5: Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM fine-tuned using similarity-guided training only (DDPM-ANT w/o AN). 3.5.6: The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM fine-tuned using similarity-guided training only (DDPM-ANT w/o AN). 3.5.7: Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM fine-tuned using similarity-guided training and adversarial noise selection (DDPM-ANT as defined by Equation 8). 3.5.8: The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM fine-tuned using similarity-guided training and adversarial noise selection (DDPM-ANT as defined by Equation 8). 3.5.9: The gradients computed for DDPM show the largest angular deviation from the reference gradient. Using DDPM without AN shows a decrease in the angular difference, and the closest angular difference between the direction of the gradient and the reference was achieved by the proposed method DDPM-ANT. 3.6: Figure 2b and Figure 2c have been replicated. 3.6.1: Code has been written to generate 20,000 samples using the DDPM model. 3.6.2: The DDPM model has been used to generate 20,000 samples. 3.6.3: Code has been written to generate 20,000 samples using the DDPM-ANT model. 3.6.4: The DDPM-ANT model has been used to generate 20,000 samples. 3.6.5: The samples generated by DDPM-ANT has a larger concentration of samples around -1,  which is the mean of the target distribution, than DDPM. 4: Figure 3 has been replicated. 4.1: The 10-shot image generation for adapting LSUN Church to Landscape drawings have been replicated. 4.1.1: Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the CDC model. 4.1.2: The CDC model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings. 4.1.3: Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DCL model. 4.1.4: The DCL model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings. 4.1.5: Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DDPM-PA model. 4.1.6: The DDPM-PA model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings. 4.1.7: Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DDPM-ANT model. 4.1.8: The DDPM-ANT model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings. 4.1.9: Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the LDM-ANT model. 4.1.10: The LDM-ANT model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings. 4.1.11: The images generated by DDPM-ANT and LDM-ANT show better results at capturing the style of landscapes and representing buildings from the source domain. 4.1.12: The images generated by CDC and DCL capture the color scheme of the target domain, but fail to capture the structure of the source domain. 4.1.13: The images generated by DDPM-PA capture the structure of the source domain, but fail to capture the color scheme of the target domain. 4.2: The 10-shot image generation for adapting FFHQ to Raphael\\'s paintings has been replicated. 4.2.1: Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings using the CDC model. 4.2.2: The CDC model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings. 4.2.3: Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings using the DCL model. 4.2.4: The DCL model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings. 4.2.5: Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings using the DDPM-PA model. 4.2.6: The DDPM-PA model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings. 4.2.7: Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings using the DDPM-ANT model. 4.2.8: The DDPM-ANT model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings. 4.2.9: Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings using the LDM-ANT model. 4.2.10: The LDM-ANT model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael\\'s paintings. 4.2.11: The images generated by CDC and DCL capture the style of the target domain, but the generated images are blurry or distorted. 4.2.12: The images generated by DDPM-PA are clear, but fail to capture the style of the target domain. 4.2.13: The images generated by DDPM-ANT and LDM-ANT results at better capture the style of the target domain, while being less blurry or distorted than those generated by CDC and DCL. 5: Table 1 has been replicated. 5.1: The results for TGAN have been replicated. 5.1.1: Code has been written to update all parameters of TGAN during fine-tuning. 5.1.2: All parameters of TGAN were updated during fine-tuning. 5.1.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using TGAN was approximately 0.510. 5.1.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using TGAN was approximately 0.550. 5.1.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using TGAN was approximately 0.533. 5.1.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using TGAN was approximately 0.585. 5.1.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using TGAN was approximately 0.601. 5.2: The results for TGAN+ADA have been replicated. 5.2.1: Code has been written to update all parameters of TGAN+ADA during fine-tuning. 5.2.2: All parameters of the model were updated during fine-tuning of TGAN+ADA. 5.2.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using TGAN+ADA was approximately 0.546.  5.2.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using TGAN+ADA was approximately 0.571. 5.2.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using TGAN+ADA was approximately 0.546.  5.2.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using TGAN+ADA was approximately 0.615. 5.2.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using TGAN+ADA was approximately 0.643. 5.3: The results for EWC have been replicated. 5.3.1: Code has been written to update all parameters of EWC during fine-tuning. 5.3.2: All parameters of the model were updated during fine-tuning of EWC. 5.3.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using EWC was approximately 0.560.  5.3.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using EWC was approximately 0.550.  5.3.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using EWC was approximately 0.541.  5.3.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using EWC was approximately 0.579. 5.3.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using EWC was approximately 0.596. 5.4: The results for CDC have been replicated. 5.4.1: Code has been written to update all parameters of CDC during fine-tuning. 5.4.2: All parameters of the model were updated during fine-tuning of CDC. 5.4.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using CDC was approximately 0.583.  5.4.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using CDC was approximately 0.581.  5.4.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using CDC was approximately 0.564.  5.4.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using CDC was approximately 0.620. 5.4.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using CDC was approximately 0.674. 5.5: The results for DCL have been replicated. 5.5.1: Code has been written to update all parameters of DCL during fine-tuning. 5.5.2: All parameters of the model were updated during fine-tuning of DCL. 5.5.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DCL was approximately 0.579.  5.5.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DCL was approximately 0.574.  5.5.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using DCL was approximately 0.558.  5.5.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DCL was approximately 0.616. 5.5.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DCL was approximately 0.626. 5.6: The results for DDPM-PA have been replicated. 5.6.1: Code has been written to update all parameters of DDPM-PA during fine-tuning. 5.6.2: All parameters of the models were updated during fine-tuning of DDPM-PA. 5.6.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DDPM-PA was approximately 0.599.  5.6.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DDPM-PA was approximately 0.604.  5.6.5: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using DDPM-PA was approximately 0.581.  5.6.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DDPM-PA was approximately 0.628. 5.6.7: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DDPM-PA was approximately 0.706. 5.7: The results for DDPM-ANT have been replicated. 5.7.1: Only 1.3% of the total number of parameters of the model were updated during fine-tuning of DDPM-ANT. 5.7.2: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DDPM-ANT was approximately 0.592.  5.7.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DDPM-ANT was approximately 0.613.  5.7.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using DDPM-ANT was approximately 0.621.  5.7.5: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DDPM-ANT was approximately 0.648. 5.7.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DDPM-ANT was approximately 0.723. 5.8: The results for LDM-ANT have been replicated. 5.8.1: Only 1.6% of the total number of parameters of the model were updated during fine-tuning of LDM-ANT.  5.8.2: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using LDM-ANT was approximately 0.601.  5.8.3: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using LDM-ANT was approximately 0.613.  5.8.4: The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael\\'s painting using LDM-ANT was approximately 0.592.  5.8.5: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using LDM-ANT was approximately 0.653. 5.8.6: The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using LDM-ANT was approximately 0.738. 6: Table 2 has been replicated. 6.1: The results for TGAN have been replicated. 6.1.1: The FID score using TGAN for 10-shot transfer from FFHQ to Babies is approximately 104. 6.1.2: The FID score using TGAN for 10-shot transfer from FFHQ to Sunglasses is approximately 55. 6.2: The results for ADA have been replicated.  6.2.1: The FID score using ADA for 10-shot transfer from FFHQ to Babies is approximately 102. 6.2.2: The FID score using ADA for 10-shot transfer from FFHQ to Sunglasses is approximately 53. 6.3: The results for EWC have been replicated.  6.3.1: The FID score using EWC for 10-shot transfer from FFHQ to Babies is approximately 87. 6.3.2: The FID score using EWC for 10-shot transfer from FFHQ to Sunglasses is approximately 59. 6.4: The results for CDC have been replicated.  6.4.1: The FID score using CDC for 10-shot transfer from FFHQ to Babies is approximately 74. 6.4.2: The FID score using CDC for 10-shot transfer from FFHQ to Sunglasses is approximately 42. 6.5: The results for DCL have been replicated.  6.5.1: The FID score using DCL for 10-shot transfer from FFHQ to Babies is approximately 52. 6.5.2: The FID score using DCL for 10-shot transfer from FFHQ to Sunglasses is approximately 38. 6.6: The results for DDPM-PA have been replicated.  6.6.1: The FID score using DDPM-PA for 10-shot transfer from FFHQ to Babies is approximately 48. 6.6.2: The FID score using DDPM-PA for 10-shot transfer from FFHQ to Sunglasses is approximately 34. 6.7: The results for ANT have been replicated.  6.7.1: The FID score using ANT for 10-shot transfer from FFHQ to Babies is approximately 46. 6.7.2: The FID score using ANT for 10-shot transfer from FFHQ to Sunglasses is approximately 20. 7: Figure 4 has been replicated. 7.1: Code has been written to fine-tune the DPM model on a 10-shot sunglasses dataset for 300 iterations. 7.2: The DPM model was fine-tuned on a 10-shot sunglasses dataset for 300 iterations. 7.3: Code has been written to fine-tune the DPM model using an adaptor layer on a 10-shot sunglasses dataset for 300 iterations, updating only the adaptor layer. 7.4: The DPM model was fine-tuned using an adaptor layer on a 10-shot sunglasses dataset for 300 iterations, updating only the adaptor layer. 7.5: Code has been written to fine-tune the DPM model using only similarity guided training on a 10-shot sunglasses dataset for 300 iterations. 7.6: The DPM model was fine-tuned using only similarity guided training on a 10-shot sunglasses dataset for 300 iterations. 7.7: Code has been written to fine-tune the DPM model using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations. 7.8: The DPM model was fine-tuned using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations. 7.9: Code has been written to fine-tune the DPM model using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations. 7.10: DPM-ANT generated images show better quality and detail than the other ones. 7.11: The adaptor results have the highest FID score, followed by the baseline results. DPM-ANT w/o AN achieve a lower FID score while the proposed DPM-ANT has the smallest FID score. 7.12: Both DPM-ANT w/o AN and the proposed DPM ANT successfully transfer sunglasses to all images. The baseline and adaptor methods both fail to transfer sunglasses to some of the images generated. 8: Table 3 has been replicated. 8.1: The results for the 10-shot classifier have been replicated. 8.1.1: Code has been written to use the DPM-ANT model to transfer FFHQ to Sunglasses, and train a classifier on 10 adapted images. 8.1.2: The DPM-ANT model was used to transfer FFHQ to Sunglasses, and a classifier was trained on 10 adapted images. 8.1.3: The intra-LPIPS score of the 10-shot classifier is approximately 0.613. 8.1.4: The FID score of the 10-shot classifier is approximately 20. 8.2: The results for the 100-shot classifier have been replicated. 8.2.1: Code has been written to use the DPM-ANT model to transfer FFHQ to Sunglasses, and train a classifier on 100 adapted images. 8.2.2: The DPM-ANT model was used to transfer FFHQ to Sunglasses, and a classifier was trained on 100 adapted images. 8.2.3: The intra-LPIPS score of the 100-shot classifier is approximately 0.637. 8.2.4: The FID score of the 100-shot classifier is approximately 22.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d13809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    reasoning={\"effort\": \"medium\"},\n",
    "    temperature=0.2,\n",
    "    input=[\n",
    "        {            \"role\": \"developer\",\n",
    "            \"content\": developer_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": file.id,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"ROOT: The paper 'All-in-one simulation-based inference' has been reproduced.\",\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dd735d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputText(annotations=[], text=\"ROOT: The paper 'All-in-one simulation-based inference' has been reproduced.\\n\\n1: The Simformer method enabling all-in-one amortized SBI has been implemented and validated.\\n1.1: The tokenizer has been implemented to encode each variable (parameter or datum) as a token with (a) ID embedding, (b) value embedding, and (c) condition-state embedding.\\n1.2: Random condition masks MC are sampled per batch across joint, posterior, likelihood, and two randomly drawn masks as described in Appendix A2.\\n1.3: Attention masks ME have been implemented for both undirected and directed graphical structures, including dynamic mask adaptation for directed cases under conditioning (Webb et al., 2018).\\n1.4: The transformer score network has been implemented with the reported configuration (token dim 50, 4 heads, attention size 10, widening factor 3; 6 layers for benchmarks; 8 layers for Lotka-Volterra, SIRD, Hodgkin–Huxley).\\n1.5: Diffusion time embedding (128-dim random Fourier features) has been implemented and injected into the transformer.\\n1.6: The VESDE and VPSDE setups have been implemented with σmin=1e-4, σmax=15, βmin=0.01, βmax=10 on t in [1e-5, 1].\\n1.7: The denoising score matching loss has been implemented exactly as ℓ(ϕ, MC, t, x̂0, x̂t) for partially noised samples x̂MCt and trained with Adam, batch size 1000, early stopping.\\n1.8: Reverse SDE sampling with Euler–Maruyama has been implemented for arbitrary conditionals by clamping conditioned variables and diffusing unobserved ones.\\n1.9: The guided diffusion procedure for interval and general constraints has been implemented per Algorithm 1 with configurable self-recurrence steps r and scaling s(t)=1/σ(t)^2.\\n1.10: Post-hoc prior/likelihood modification via score decomposition s(θ|x) ≈ s(θ)+[s(θ|x)−s(θ)] with scaling and shifting (α,β) has been implemented as in Appendix A1.3.\\n1.11: Unit tests verify that the model samples arbitrary conditionals p(θ|x), p(x|θ), and mixed conditionals on the Two Moons simulator (qualitatively matching Fig. 3).\\n\\n2: Benchmark performance against baselines has been replicated (Fig. 4 and Appendices A5–A8).\\n2.1: The four SBIBM benchmark simulators have been implemented per Appendix A2 (Linear Gaussian, Mixture Gaussian, Two Moons, SLCP).\\n2.2: The Tree and HMM simulators for “all conditionals” have been implemented per Appendix A2.\\n2.3: Ground-truth samples for posteriors and arbitrary conditionals have been generated with the specified MCMC procedures for each task (Appendix A2).\\n2.4: Baselines NPE, NLE, NRE, and NPSE have been trained using sbi defaults with neural spline flows where applicable and early stopping.\\n2.5: Simformer models have been trained with (a) dense attention, (b) undirected structured mask, and (c) directed structured mask per task.\\n2.6: Posterior C2ST curves vs number of simulations (1e3, 1e4, 1e5) have been reproduced showing Simformer ≤ NPE C2ST on 3–4/4 tasks across budgets, with the Linear Gaussian 10k exception, matching Fig. 4a trends.\\n2.7: “All conditionals” C2ST curves for Tree, HMM, Two Moons, SLCP have been reproduced with Simformer accurately modeling arbitrary conditionals and structured masks improving accuracy (Fig. 4b).\\n2.8: Extended comparisons reproduce the relative rankings vs NLE/NRE/NPSE under VESDE and VPSDE (Appendix Figs. A5–A6).\\n2.9: The evaluation-steps sensitivity has been reproduced: ≥50 reverse-SDE steps achieves near-best C2ST on all tasks except Two Moons with VPSDE (Fig. A7).\\n2.10: Average negative log-likelihoods via probability-flow ODE have been computed for posterior and likelihood, broadly agreeing with C2ST and showing cases where NLE/NPE lead on NLL (Fig. A8).\\n\\n3: Lotka–Volterra unstructured-observation inference has been replicated (Fig. 5).\\n3.1: The ODE simulator with Gaussian observation noise has been implemented per Appendix A2 with flexible, irregular observation times and missing channels.\\n3.2: A Simformer has been trained on 1e5 simulations with the Lotka–Volterra dependency masks (including dynamic adaptation to input times).\\n3.3: Scenario 1 has been reproduced: 4 irregular prey observations only; posterior shows true parameters within high-density regions; posterior predictive matches observations (Fig. 5a).\\n3.4: Scenario 2 has been reproduced: adding 9 predator observations reduces posterior and posterior-predictive uncertainty (Fig. 5b).\\n3.5: C2ST for posterior and all conditionals confirms close agreement with MCMC ground truth (Fig. 5c).\\n\\n4: SIRD with infinite-dimensional (time-dependent) parameters and parameter-conditioned inference has been replicated (Fig. 6).\\n4.1: The SIRD simulator has been implemented with time-varying contact rate β(t) drawn from a GP, constant recovery and death rates, and log-normal observation noise (Appendix A2).\\n4.2: The tokenizer encodes function-valued parameters using shared ID embeddings plus random Fourier embeddings of time indices.\\n4.3: Training on irregular I, R, D observations reproduces posteriors: realistic γ, μ and β(t) with increased uncertainty where infections vanish (Fig. 6a).\\n4.4: Posterior predictives generated without re-simulating match observed data (Fig. 6a, right panels).\\n4.5: Parameter-conditioned posteriors have been reproduced with partial β(t) measurements and a single fatalities measurement, aligning with constraints and data (Fig. 6b).\\n4.6: Expected coverage analyses confirm well-calibrated conditional distributions (Appendix Fig. A13).\\n\\n5: Hodgkin–Huxley inference with observation-interval constraints via guided diffusion has been replicated (Fig. 7).\\n5.1: The Hodgkin–Huxley model has been implemented per Pospischil et al. (2008), with summary features for voltage and energy computed from sodium charge (Appendix A2).\\n5.2: A Simformer posterior conditioned on voltage summaries (without energy) has been reproduced, matching broad/narrow marginals as reported (Fig. 7b).\\n5.3: Posterior predictive energy distribution generated by Simformer matches simulator-derived predictive energy (Fig. 7c–d).\\n5.4: An energy-interval constraint (lowest 10% quantile) has been enforced using guided diffusion; the constrained posterior tightens gNa and gK as reported (Fig. 7e).\\n5.5: Constrained posterior predictives satisfy the energy threshold while voltage traces remain consistent with observations (Fig. 7f–g).\\n\\n6: Additional appendix experiments and analyses have been replicated (Appendix A1–A3).\\n6.1: Conditional/marginalization properties have been verified on a toy example: training with dense+identity+pairwise masks yields correct marginals even when variables are dropped (Fig. A2).\\n6.2: Post-hoc prior/likelihood adaptations and general constraints have been validated on the toy model (Fig. A3), reproducing expected shifts/narrowings under α,β changes.\\n6.3: Gravitational waves example has been reproduced using a CNN embedding as a single token; full and partial posteriors p(θ|x1,x2), p(θ|x1), p(θ|x2) match coverage (Fig. A14).\\n6.4: Guidance-only conditioning has been benchmarked when training on the joint only: self-recurrence (r=5) closes the gap to model-based conditioning at ~5× compute (Fig. A15).\\n6.5: General constraint enforcement with guidance has been reproduced on Two Moons, including multi-constraint scenarios and comparison to RePaint, showing improvement with self-recurrence (Fig. A16).\\n\\n7: Reproducibility infrastructure has been established.\\n7.1: The environment has been set up with JAX and hydra per paper; sbi library is used for baselines.\\n7.2: All configurations (SDE choice, masks, transformer hyperparameters, batch sizes, optimizer settings, training budgets) are tracked and versioned.\\n7.3: Random seeds are fixed and logged for simulations, training, and MCMC runs.\\n7.4: The public code repository has been cloned and local modifications (if any) are documented; scripts reproduce all figures and metrics end-to-end.\", type='output_text', logprobs=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[1].content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c45bc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_689ccacc953881958a27017dd39b3c4c048d052b575aefe7', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseOutputMessage(id='msg_689ccb08751c819585605229f17beee1048d052b575aefe7', content=[ResponseOutputText(annotations=[], text=\"ROOT: The paper 'All-in-one simulation-based inference' has been reproduced.\\n\\n1: The Simformer method enabling all-in-one amortized SBI has been implemented and validated.\\n1.1: The tokenizer has been implemented to encode each variable (parameter or datum) as a token with (a) ID embedding, (b) value embedding, and (c) condition-state embedding.\\n1.2: Random condition masks MC are sampled per batch across joint, posterior, likelihood, and two randomly drawn masks as described in Appendix A2.\\n1.3: Attention masks ME have been implemented for both undirected and directed graphical structures, including dynamic mask adaptation for directed cases under conditioning (Webb et al., 2018).\\n1.4: The transformer score network has been implemented with the reported configuration (token dim 50, 4 heads, attention size 10, widening factor 3; 6 layers for benchmarks; 8 layers for Lotka-Volterra, SIRD, Hodgkin–Huxley).\\n1.5: Diffusion time embedding (128-dim random Fourier features) has been implemented and injected into the transformer.\\n1.6: The VESDE and VPSDE setups have been implemented with σmin=1e-4, σmax=15, βmin=0.01, βmax=10 on t in [1e-5, 1].\\n1.7: The denoising score matching loss has been implemented exactly as ℓ(ϕ, MC, t, x̂0, x̂t) for partially noised samples x̂MCt and trained with Adam, batch size 1000, early stopping.\\n1.8: Reverse SDE sampling with Euler–Maruyama has been implemented for arbitrary conditionals by clamping conditioned variables and diffusing unobserved ones.\\n1.9: The guided diffusion procedure for interval and general constraints has been implemented per Algorithm 1 with configurable self-recurrence steps r and scaling s(t)=1/σ(t)^2.\\n1.10: Post-hoc prior/likelihood modification via score decomposition s(θ|x) ≈ s(θ)+[s(θ|x)−s(θ)] with scaling and shifting (α,β) has been implemented as in Appendix A1.3.\\n1.11: Unit tests verify that the model samples arbitrary conditionals p(θ|x), p(x|θ), and mixed conditionals on the Two Moons simulator (qualitatively matching Fig. 3).\\n\\n2: Benchmark performance against baselines has been replicated (Fig. 4 and Appendices A5–A8).\\n2.1: The four SBIBM benchmark simulators have been implemented per Appendix A2 (Linear Gaussian, Mixture Gaussian, Two Moons, SLCP).\\n2.2: The Tree and HMM simulators for “all conditionals” have been implemented per Appendix A2.\\n2.3: Ground-truth samples for posteriors and arbitrary conditionals have been generated with the specified MCMC procedures for each task (Appendix A2).\\n2.4: Baselines NPE, NLE, NRE, and NPSE have been trained using sbi defaults with neural spline flows where applicable and early stopping.\\n2.5: Simformer models have been trained with (a) dense attention, (b) undirected structured mask, and (c) directed structured mask per task.\\n2.6: Posterior C2ST curves vs number of simulations (1e3, 1e4, 1e5) have been reproduced showing Simformer ≤ NPE C2ST on 3–4/4 tasks across budgets, with the Linear Gaussian 10k exception, matching Fig. 4a trends.\\n2.7: “All conditionals” C2ST curves for Tree, HMM, Two Moons, SLCP have been reproduced with Simformer accurately modeling arbitrary conditionals and structured masks improving accuracy (Fig. 4b).\\n2.8: Extended comparisons reproduce the relative rankings vs NLE/NRE/NPSE under VESDE and VPSDE (Appendix Figs. A5–A6).\\n2.9: The evaluation-steps sensitivity has been reproduced: ≥50 reverse-SDE steps achieves near-best C2ST on all tasks except Two Moons with VPSDE (Fig. A7).\\n2.10: Average negative log-likelihoods via probability-flow ODE have been computed for posterior and likelihood, broadly agreeing with C2ST and showing cases where NLE/NPE lead on NLL (Fig. A8).\\n\\n3: Lotka–Volterra unstructured-observation inference has been replicated (Fig. 5).\\n3.1: The ODE simulator with Gaussian observation noise has been implemented per Appendix A2 with flexible, irregular observation times and missing channels.\\n3.2: A Simformer has been trained on 1e5 simulations with the Lotka–Volterra dependency masks (including dynamic adaptation to input times).\\n3.3: Scenario 1 has been reproduced: 4 irregular prey observations only; posterior shows true parameters within high-density regions; posterior predictive matches observations (Fig. 5a).\\n3.4: Scenario 2 has been reproduced: adding 9 predator observations reduces posterior and posterior-predictive uncertainty (Fig. 5b).\\n3.5: C2ST for posterior and all conditionals confirms close agreement with MCMC ground truth (Fig. 5c).\\n\\n4: SIRD with infinite-dimensional (time-dependent) parameters and parameter-conditioned inference has been replicated (Fig. 6).\\n4.1: The SIRD simulator has been implemented with time-varying contact rate β(t) drawn from a GP, constant recovery and death rates, and log-normal observation noise (Appendix A2).\\n4.2: The tokenizer encodes function-valued parameters using shared ID embeddings plus random Fourier embeddings of time indices.\\n4.3: Training on irregular I, R, D observations reproduces posteriors: realistic γ, μ and β(t) with increased uncertainty where infections vanish (Fig. 6a).\\n4.4: Posterior predictives generated without re-simulating match observed data (Fig. 6a, right panels).\\n4.5: Parameter-conditioned posteriors have been reproduced with partial β(t) measurements and a single fatalities measurement, aligning with constraints and data (Fig. 6b).\\n4.6: Expected coverage analyses confirm well-calibrated conditional distributions (Appendix Fig. A13).\\n\\n5: Hodgkin–Huxley inference with observation-interval constraints via guided diffusion has been replicated (Fig. 7).\\n5.1: The Hodgkin–Huxley model has been implemented per Pospischil et al. (2008), with summary features for voltage and energy computed from sodium charge (Appendix A2).\\n5.2: A Simformer posterior conditioned on voltage summaries (without energy) has been reproduced, matching broad/narrow marginals as reported (Fig. 7b).\\n5.3: Posterior predictive energy distribution generated by Simformer matches simulator-derived predictive energy (Fig. 7c–d).\\n5.4: An energy-interval constraint (lowest 10% quantile) has been enforced using guided diffusion; the constrained posterior tightens gNa and gK as reported (Fig. 7e).\\n5.5: Constrained posterior predictives satisfy the energy threshold while voltage traces remain consistent with observations (Fig. 7f–g).\\n\\n6: Additional appendix experiments and analyses have been replicated (Appendix A1–A3).\\n6.1: Conditional/marginalization properties have been verified on a toy example: training with dense+identity+pairwise masks yields correct marginals even when variables are dropped (Fig. A2).\\n6.2: Post-hoc prior/likelihood adaptations and general constraints have been validated on the toy model (Fig. A3), reproducing expected shifts/narrowings under α,β changes.\\n6.3: Gravitational waves example has been reproduced using a CNN embedding as a single token; full and partial posteriors p(θ|x1,x2), p(θ|x1), p(θ|x2) match coverage (Fig. A14).\\n6.4: Guidance-only conditioning has been benchmarked when training on the joint only: self-recurrence (r=5) closes the gap to model-based conditioning at ~5× compute (Fig. A15).\\n6.5: General constraint enforcement with guidance has been reproduced on Two Moons, including multi-constraint scenarios and comparison to RePaint, showing improvement with self-recurrence (Fig. A16).\\n\\n7: Reproducibility infrastructure has been established.\\n7.1: The environment has been set up with JAX and hydra per paper; sbi library is used for baselines.\\n7.2: All configurations (SDE choice, masks, transformer hyperparameters, batch sizes, optimizer settings, training budgets) are tracked and versioned.\\n7.3: Random seeds are fixed and logged for simulations, training, and MCMC runs.\\n7.4: The public code repository has been cloned and local modifications (if any) are documented; scripts reproduce all figures and metrics end-to-end.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
