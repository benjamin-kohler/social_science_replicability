
# Goal
The goal is to develop a multi-step / multi-agent system that automatically runs a replication of a social science paper.

# System
## Step 1 / Agent 1: Extractor of main results and methods from paper
- This agent should receive a paper in pdf as input. 
- The agent should return a structured document which serves as the input for Agent 2. 
- The structured document should contain
    - the research question(s)
    - brief descriptions of data and context relevant for the analysis 
    - methods used in the main analysis of the paper, including
        - all data processing, filtering and cleaning steps
        - all specifications of regressions
        - all tables in the main analysis, including column and row names and captions without revealing actual results. 
        - descriptions of all plots including plot type, axis names, and captions in the main analysis without revealing actual results-
- The outputted document MUST NOT reveal any actual outcomes or results.

## Step 2 / Agent 2: Replicator
- This agent receives the data and the structured document from step 1 as input
- The agent should output all tables and plots from the original paper based on the methodological summary
- The agent should generate the output by writing code that replicates the results of the original paper using the provided data and the structured document
- The agent should use Python to generate results if possible and otherwise is allowed to use R
- The agent MUST NOT access the original paper or the original results



## Step 3 / Agent 3: Verifier
- This agent receives the original paper as pdf and the replicated results from the agent of Step 2 as input
- It should return a classifcation for each plot and table that tells whether the agent was able to replicate the result from the original paper as well as an overall classification of the reproduction effort.
- The classification should only be based on the actual results, not differences in formatting or styling.
- The classification should take on the following classes:
    - A: Fully replicated the results.
    - B: Replicated the results with the same direction of effects and trends but small discrepencies in the numerical outcomes.
    - C: Replicated the results with the same direction of effects and trends but large discrepencies in the numerical outcomes.
    - D: Did not replicate the results, the replicated effects or trends relevantly differ from the orignal results. The effects might be non-detectable or even pointing in opposite directions 
    - F: The results are not comparable because either the replicator did not generate a result or the formatting differs so substantially that a judgment is impossible.


## Step 4 / Agent 4: Explaining / Reasoning
- This agent receives the original paper as pdf, the summary generated by Step 1, the code generated by Step 2, the results generated by Step 2, the grades by Step 3, and the replication package of the original paper as input
- For every replicated table or plot step that did not receive grade A, it should generate a short report. 
- The report should contain 
    - a description of the descripancies between the replicated and original results
    - an analysis why these discrepencies occured
    - a classification of the reasons for why this error occured is identifiable from the documents or should not occur (e.g., because a different code was used to generate the results than in the replication package). This classification should be binary
    - a judgment of given the papers intend and research queston whether these discrepencies are rather the fault of the replicator (e.g., because they used wrong assumptions or misspecified a method) or by the orignal paper (e.g., by using implausible data cleaning steps, wrong assumptions)





# Methods
- The code for this multi-agent system should use the open agent framework so that underlying models can easily switched
- The code for this system should be entirely in python
- The code should be well documented in a readme file
- All runs of the main function should generate a json report on the exact specifications that were used to run it 

